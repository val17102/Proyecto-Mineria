---
title: "Proyecto No.1"
author: "Héctor Valle, Rodrigo Samayoa & Paul Belches"
date: "23/3/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ggpubr)
library(dplyr)
theme_set(theme_pubr())
datos<-read.csv("INE-Accidentes-Guatemala.csv", stringsAsFactors = FALSE)
datos<-na.omit(datos)
datos <- datos[which(datos$depto_ocu == "Guatemala"), ]
```

```{r}
datos$mes <- 0
datos[which(datos$mes_ocu == "Enero"), ]$mes <- 1
datos[which(datos$mes_ocu == "Febrero"), ]$mes <- 2
datos[which(datos$mes_ocu == "Marzo"), ]$mes <- 3
datos[which(datos$mes_ocu == "Abril"), ]$mes <- 4
datos[which(datos$mes_ocu == "Mayo"), ]$mes <- 5
datos[which(datos$mes_ocu == "Junio"), ]$mes <- 6
datos[which(datos$mes_ocu == "Julio"), ]$mes <- 7
datos[which(datos$mes_ocu == "Agosto"), ]$mes <- 8
datos[which(datos$mes_ocu == "Septiembre"), ]$mes <- 9
datos[which(datos$mes_ocu == "Octubre"), ]$mes <- 10
datos[which(datos$mes_ocu == "Noviembre"), ]$mes <- 11
datos[which(datos$mes_ocu == "Diciembre"), ]$mes <- 12
datos
```

```{r}
#Limpieza de Datos de Insivumeh
library(readxl)

datosInsi <- read_xlsx("Insivumeh.xlsx")
datosInsi<-datosInsi[,-c(8, 9, 10, 11, 13, 14, 17)]
names(datosInsi)[1] <- "year"
names(datosInsi)[2] <- "mes"	
names(datosInsi)[3] <- "dia_ocu"
names(datosInsi)[4] <- "tempMax"
names(datosInsi)[5] <- "tempMin"
names(datosInsi)[6] <- "tempMed"
names(datosInsi)[7] <- "lluviaMed"
names(datosInsi)[8] <- "nuboMedia"
names(datosInsi)[9] <- "humeRelMedia"
names(datosInsi)[10] <- "presionAtmMedia"
```

#Data correction
```{r}
#Arreglo de Na, asignación de valores promedio
datosInsi$tempMax[is.na(datosInsi$tempMax)] <-25.66
datosInsi$tempMin[is.na(datosInsi$tempMin)] <-15.56
datosInsi$tempMed[is.na(datosInsi$tempMed)] <- 19.97
datosInsi$lluviaMed[is.na(datosInsi$lluviaMed)] <-3.49
datosInsi$nuboMedia[is.na(datosInsi$nuboMedia)] <-5.667
datosInsi$presionAtmMedia[is.na(datosInsi$presionAtmMedia)] <-640.7
```

```{r}
dataMezclada <- merge(x = datos, y = datosInsi, by = c("mes","year","dia_ocu"))
dataMezclada<-dataMezclada[,-c(9)]
dataMezclada
```

```{r}
#Convertir variables categoritas a numericas categoricas
dataMezclada$mes_ocu <- as.numeric(factor(dataMezclada$mes_ocu))
dataMezclada$dia_sem_ocu <- as.numeric(factor(dataMezclada$dia_sem_ocu))
dataMezclada$dia_sem_ocu <- as.numeric(factor(dataMezclada$dia_sem_ocu))
dataMezclada$depto_ocu <- as.numeric(factor(dataMezclada$depto_ocu))
dataMezclada$mupio_ocu <- as.numeric(factor(dataMezclada$mupio_ocu))
dataMezclada$sexo_fall_les <- as.numeric(factor(dataMezclada$sexo_fall_les))
dataMezclada$tipo_vehi <- as.numeric(factor(dataMezclada$tipo_vehi))
dataMezclada$color_vehi <- as.numeric(factor(dataMezclada$color_vehi))
dataMezclada$causa_acc <- as.numeric(factor(dataMezclada$causa_acc))
dataMezclada$estado_implicado <- as.numeric(factor(dataMezclada$estado_implicado))
dataMezclada[2:3] <- lapply(dataMezclada[2:3], as.numeric)
dataMezclada[6] <- lapply(dataMezclada[6], as.numeric)
dataMezclada[10] <- lapply(dataMezclada[10], as.numeric)
dataMezclada
```

```{r}
#Matriz de correlación de los datos
library(corrplot)
matriz_cor <- cor(dataMezclada)
corrplot(matriz_cor)
```

```{r}
#Eliminacipon de variables, mes duplicado, temp max y min, departamento y edad del fallecido
dataMezclada <- dataMezclada[,-c(15,16)]
dataMezclada[,-c(1,7,10)]
dataMezclada
dataMezclada <-dataMezclada[,-c(1,7,10)]
```

```{r}
#División de datos para prueba y entrenamiento
porciento <- 70/100
set.seed(123)

trainRowsNumber<-sample(1:nrow(dataMezclada),porciento*nrow(dataMezclada))
train<-dataMezclada[trainRowsNumber,]
test<-dataMezclada[-trainRowsNumber,]
```


```{r}
#Balanceo de datos
unos <-train[which(train$estado_implicado == 1), ]
nrow(unos)
nrow (train[which(train$estado_implicado == 2), ])
```

```{r}
#Balanceo de datos
balanceado <- rbind(train, unos)
balanceado <- rbind(balanceado, unos)
balanceado <- rbind(balanceado, unos)
balanceado <- rbind(balanceado, unos)
balanceado <- rbind(balanceado, unos)
balanceado <- rbind(balanceado, unos)
```

```{r}
#Balanceo de datos
nrow (balanceado[which(balanceado$estado_implicado == 1), ])
nrow (balanceado[which(balanceado$estado_implicado == 2), ])
```

```{r}
#Balanceo de datos
train <- balanceado
```

```{r}
#Eliminar Na
train<-na.omit(train)
test<-na.omit(test)
```

```{r}
train[,c(-11)]
```


#Random Forest
```{r}
library(randomForest)
library(rpart)
library(caret)
library(tree)
```


```{r}
modeloRF1<-randomForest(train$estado_implicado~.,data=train)
prediccionRF1<-predict(modeloRF1,newdata = test)
testCompleto<-test
testCompleto$predRF<-round(prediccionRF1)
```

```{r}
cfmRandomForest <- confusionMatrix(table(testCompleto$predRF, testCompleto$estado_implicado))
cfmRandomForest

#En el caso de random forest podemos observar que se obtuvo una exactitud de 87.16%, 63 falsos positivos y 653 falsos negativos. El valor de capa es pequeños, por lo que existe un alto factor de aleatoriedad en el modelo . Y que el valor del No Information rate, sea más alto que la exactitud nos indica que  la selección de la clase mayoritaria de forma arbitraria, no daría una mayor exactitud qué la qué tenemos por parte del modelo. 
```


#Naive Bayes

```{r}
train2 <- rbind(train, train)
```


```{r}
library(naivebayes)
modeloNb<-naive_bayes(train[,c(-11)], as.factor(train[,11]))
predBayes<-predict(modeloNb,  test[,-6])
test$predic<-predBayes
confusionMatrix(table(test$estado_implicado,test$predic))
#En el caso de naive bayes podemos observar que se obtuvo una exactitud de 60.36%, 222 falsos positivos y 2278 falsos negativos. El valor de capa es pequeños, por lo que existe un alto factor de aleatoriedad en el modelo . Aunque tomando en cuenta el bajo valor de exactitud podríamos indicar que se encuentra acorde con el modelo. 
```


## Regresión Logística

```{r}
porciento <- 70/100
set.seed(123)
dataMezclada2 <- dataMezclada
dataMezclada2$uno <- 0
dataMezclada2$dos <- 0


dataMezclada2[which(dataMezclada2$estado_implicado == 1), ]$uno <- 1
dataMezclada2[which(dataMezclada2$estado_implicado == 2), ]$dos <- 1
dataMezclada2
#dataMezclada2 <- cbind(dataMezclada2,dummy(dataMezclada2$estado_implicado,verbose = T))

#trainRowsNumber<-sample(1:nrow(dataMezclada),porciento*nrow(dataMezclada))
#train<-dataMezclada[trainRowsNumber,]
#test<-dataMezclada[-trainRowsNumber,]
```

```{r}
dataMezclada2<-dataMezclada2[,-c(11)]
```

```{r}
porciento <- 70/100
set.seed(123)

trainRowsNumber<-sample(1:nrow(dataMezclada2),porciento*nrow(dataMezclada2))
train<-dataMezclada2[trainRowsNumber,]
test<-dataMezclada2[-trainRowsNumber,]
```


```{r}
#Balanceo de datos
unos <-train[which(train$uno == 1), ]
nrow(unos)
nrow (train[which(train$uno == 0), ])
```

```{r}
#Balanceo de datos
balanceado <- rbind(train, unos)
balanceado <- rbind(balanceado, unos)
balanceado <- rbind(balanceado, unos)
balanceado <- rbind(balanceado, unos)
balanceado <- rbind(balanceado, unos)
balanceado <- rbind(balanceado, unos)
```

```{r}
#Balanceo de datos
nrow (balanceado[which(balanceado$uno == 1), ])
nrow (balanceado[which(balanceado$uno == 0), ])
```

```{r}
#Balanceo de datos
train <- balanceado
```


```{r}
modeloRL<-glm(uno~., data = train[,c(1:16)],family = binomial(link='logit'), maxit=10000)
pred<-predict(modeloRL,newdata = test[,c(1:15)], type = "response")
prediccion<-ifelse(pred>=0.5,1,0)
confusionMatrix(table(test$uno,prediccion))

#En el caso de regresión logística podemos observar que se obtuvo una exactitud de 60.36%, 1965 falsos positivos y 245 falsos negativos. El valor de capa es pequeños, por lo que existe un alto factor de aleatoriedad en el modelo. Aunque tomando en cuenta el bajo valor de exactitud podríamos indicar que se encuentra acorde con el modelo. 
```

#Adaboost

```{r}
dataMezclada2[which(dataMezclada2$uno == 0), ]$uno <- -1
```

```{r}
porciento <- 70/100
set.seed(123)

trainRowsNumber<-sample(1:nrow(dataMezclada2),porciento*nrow(dataMezclada2))
train<-dataMezclada2[trainRowsNumber,]
test<-dataMezclada2[-trainRowsNumber,]
```


```{r}
#Balanceo de datos
unos <-train[which(train$uno == 1), ]
nrow(unos)
nrow (train[which(train$uno == -1), ])
```

```{r}
#Balanceo de datos
balanceado <- rbind(train, unos)
balanceado <- rbind(balanceado, unos)
balanceado <- rbind(balanceado, unos)
balanceado <- rbind(balanceado, unos)
balanceado <- rbind(balanceado, unos)
balanceado <- rbind(balanceado, unos)
```

```{r}
#Balanceo de datos
nrow (balanceado[which(balanceado$uno == 1), ])
nrow (balanceado[which(balanceado$uno == -1), ])
```

```{r}
#Balanceo de datos
train <- balanceado
```

```{r}
#library(caret)
#install.packages("JOUSBoost")
library(JOUSBoost)
dataMezclada2
model_adaboost <- adaboost(data.matrix(train[,c(-16, -17)]), train[,16], tree_depth = 3, n_rounds = 100, verbose = FALSE,control = NULL)
predAda<-predict(model_adaboost,  test[,c(-16,-17)])
```
```{r}
test$pred<-predAda
test
confusionMatrix(table(test[,16],test[,18]))

#En el caso de naive bayes podemos observar que se obtuvo una exactitud de 68.05%, 1541 falsos positivos y 240 falsos negativos. El valor de capa es pequeños, por lo que existe un alto factor de aleatoriedad en el modelo . Aunque tomando en cuenta el bajo valor de exactitud podríamos indicar que se encuentra acorde con el modelo. 

#A pesar de que el algoritmo de Random Forest , cuenta en el valor más alto de exactitud, por lo explicado anteriormente debemos de descartar lo como el mejor modelo. Por su parte Adaboost, no solo tuvo la menor cantidad de falsos negativos, 240, cuenta con el segundo mejor índice de exactitud. Es importante destacar que el análisis, no toma en cuenta los falsos positivos. Esto gracias a qué se considera que el equivocarse en la fatalidad de un accidente simple, no es de mucha prioridad. En comparación con un algoritmo que podría equivocarse a la hora de predecir la posible muerte de alguien.  

```



